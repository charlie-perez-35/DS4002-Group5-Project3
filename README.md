# DS4002-Group5-Project3


Code for various projects in DS 4002 Spring 2024. Group 5 consists of Andrea, Cato, and Charlie.

Our goal for this project is to develop a Facial Emotion Recognition (FER) model to classify facial expressions into distinct emotions. We are aiming to reach a level of accuracy comparable to human interpretation. This technology holds significant value, especially in telehealth and customer service, where understanding and reacting to human emotions is critical. By achieving this, we aim to enhance human-AI interaction and support mental health diagnostics, demonstrating the practical implications of our work in real-world applications.

## Content 
README.md -- Serves as an orientation to everyone who comes to this repository, it should enable you to get their bearings. You are in the README.md file now.    
LICENSE.md -- The terms under which they may use and cite your repository.   
SCRIPTS folder -- Contains all the source code for the project.     
DATA folder -- Contains all of the data for this project.   
OUTPUT folder -- Contains all of the output generated by our project, e.g. figures, tables, etc.   

- - - -

## Section 1: Software and platform section
Software: Python (Colab or Jupyter)

Packages: numpy, pandas, os, PIL, PIL.Image, tensorflow, tensorflow.keras, matplotlib.pyplot, shutil

Platform: Charlie and Cato used Windows, Andrea on Mac

## Section 2: Map of documentation
### What you will find in this repo:
* DATA folder:

> anger.zip: a file containing all of the images displaying "anger" available for download. All subsequent files are the same as this one, displaying the corresponding labelled emotion.

> contempt.zip

> disgust.zip

> fear.zip

> happiness.zip

> sadness.zip

> surprise.zip
  
* SCRIPTS folder:

> project3_eda.ipynb: the script we used to do initial EDA, test viability of augmentation, and view images.

* OUTPUT folder:
  
> output.pdf: compilation of our model performance results

* LICENSE.md
* README.md

## Section 3: Instructions for reproducing results
To replicate our results, first download the files in the DATA folder.

Prepare Python - Import the necessary libraries and add-on packages.  For python you will need to install/install numpy, pandas, os, PIL, PIL.Image, tensorflow, tensorflow.keras, matplotlib.pyplot, shutil

Run the master script file - In the SCRIPTS folder, download and run the project3_eda.ipynb script in python.

Analyze the results - After running the master script, it should result in some graphs and figures. Cross reference these with the graphs and figures uploaded in the OUTPUT folder. 

## Resources:

[1] World Health Organization, “COVID-19 pandemic triggers 25% increase in prevalence of anxiety and depression worldwide,” World Health Organization, Mar. 02, 2022. https://www.who.int/news/item/02-03-2022-covid-19-pandemic-triggers-25-increase-in-prevalence-of-anxiety-and-depression-worldwide

[2] T. Chamorro-Premuzic, “Why you can’t believe all the visual cues you get on video chats,” Fast Company, May 20, 2020. https://www.fastcompany.com/90506857/why-you-cant-believe-all-the-visual-cues-you-get-on-video-chats

[3] spenceryee, “CS229/CK+ at master · spenceryee/CS229,” GitHub, 2014. https://github.com/spenceryee/CS229/tree/master/CK%2B (accessed Apr. 08, 2024).

[4] G. Sharma, “Facial Emotion Recognition (FER) using Keras,” Analytics Vidhya, Sep. 23, 2020. https://medium.com/analytics-vidhya/facial-emotion-recognition-fer-using-keras-763df7946a64 (accessed Apr. 08, 2024).

[5]E. Allibhai, “Building a Convolutional Neural Network (CNN) in Keras,” Medium, Nov. 15, 2018. https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5
